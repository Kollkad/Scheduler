# backend/app/saving_results/routes/saving.py
"""
–ú–æ–¥—É–ª—å –º–∞—Ä—à—Ä—É—Ç–æ–≤ FastAPI –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Excel —Ñ–∞–π–ª—ã.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ—Ç—á–µ—Ç–æ–≤:
- –û—á–∏—â–µ–Ω–Ω—ã–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤
- –¶–≤–µ—Ç–æ–≤—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é (—Ä–∞–¥—É–≥—É)
- –†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
- –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –∞—Ä—Ö–∏–≤—ã –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
"""
import urllib
from datetime import datetime

from fastapi import APIRouter, HTTPException
from fastapi.responses import FileResponse
import pandas as pd
import tempfile
import logging

from backend.app.common.config.column_names import COLUMNS
from backend.app.common.modules.data_manager import data_manager
from backend.app.saving_results.modules.saving_results_settings import (
    generate_filename,
    save_with_xlsxwriter_formatting,
    rename_columns_to_russian, add_source_columns_to_tasks
)

router = APIRouter(prefix="/api/save", tags=["saving"])

@router.get("/available-data")
async def get_available_data_status():
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞.

    Returns:
        dict: –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤
    """
    try:
        detailed_data = data_manager.get_detailed_data()
        documents_data = data_manager.get_documents_data()

        status = {
            "detailed_report": {
                "loaded": detailed_data is not None,
                "row_count": len(detailed_data) if detailed_data is not None else 0,
            },
            "documents_report": {
                "loaded": documents_data is not None,
                "row_count": len(documents_data) if documents_data is not None else 0,
            }
        }

        return {
            "success": True,
            "status": status,
            "message": "–°—Ç–∞—Ç—É—Å –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—É—á–µ–Ω"
        }

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {str(e)}")

@router.get("/all-processed-data")
async def get_all_processed_data_status():
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ –≤—Å–µ—Ö –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

    Returns:
        dict: –°—Ç–∞—Ç—É—Å –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º—ã
    """
    try:
        detailed_data = data_manager.get_detailed_data()
        documents_data = data_manager.get_documents_data()
        lawsuit_data = data_manager.get_processed_data("lawsuit_staged")
        order_data = data_manager.get_processed_data("order_staged")
        documents_analysis_data = data_manager.get_processed_data("documents_processed")
        tasks_data = data_manager.get_processed_data("tasks")

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤ –¥–ª—è —Å—Ç–∞—Ç—É—Å–∞
        terms_productions_data = pd.concat(
            [df for df in [lawsuit_data, order_data] if df is not None and not df.empty],
            ignore_index=True
        ) if (lawsuit_data is not None or order_data is not None) else None

        status = {
            "detailed_report": {
                "loaded": detailed_data is not None,
                "row_count": len(detailed_data) if detailed_data is not None else 0,
            },
            "documents_report": {
                "loaded": documents_data is not None,
                "row_count": len(documents_data) if documents_data is not None else 0,
            },
            "terms_productions": {
                "loaded": terms_productions_data is not None and not terms_productions_data.empty,
                "row_count": len(terms_productions_data) if terms_productions_data is not None else 0,
            },
            "documents_analysis": {
                "loaded": documents_analysis_data is not None,
                "row_count": len(documents_analysis_data) if documents_analysis_data is not None else 0,
            },
            "tasks": {
                "loaded": tasks_data is not None,
                "row_count": len(tasks_data) if tasks_data is not None else 0,
            }
        }

        return {
            "success": True,
            "status": status,
            "message": "–°—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—É—á–µ–Ω"
        }

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {str(e)}")

@router.get("/detailed-report")
async def save_detailed_report():
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

    Returns:
        FileResponse: Excel —Ñ–∞–π–ª —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –æ—Ç—á–µ—Ç–æ–º

    Raises:
        HTTPException: 400 –µ—Å–ª–∏ –æ—Ç—á–µ—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω
        HTTPException: 500 –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    try:
        detailed_data = data_manager.get_detailed_data()

        if detailed_data is None or detailed_data.empty:
            raise HTTPException(status_code=400, detail="–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {len(detailed_data)} —Å—Ç—Ä–æ–∫, {len(detailed_data.columns)} –∫–æ–ª–æ–Ω–æ–∫")

        with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
            filepath = tmp_file.name

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ xlsxwriter
        save_with_xlsxwriter_formatting(detailed_data, filepath, '–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç')

        download_filename = generate_filename("detailed_report")

        return FileResponse(
            path=filepath,
            filename=download_filename,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")


@router.get("/documents-report")
async def save_documents_report():
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

    Returns:
        FileResponse: Excel —Ñ–∞–π–ª —Å –æ—Ç—á–µ—Ç–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

    Raises:
        HTTPException: 400 –µ—Å–ª–∏ –æ—Ç—á–µ—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω
        HTTPException: 500 –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    try:
        documents_data = data_manager.get_documents_data()

        if documents_data is None or documents_data.empty:
            raise HTTPException(status_code=400, detail="–û—Ç—á–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents_data)} —Å—Ç—Ä–æ–∫, {len(documents_data.columns)} –∫–æ–ª–æ–Ω–æ–∫")

        with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
            filepath = tmp_file.name

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ xlsxwriter
        save_with_xlsxwriter_formatting(documents_data, filepath, '–î–æ–∫—É–º–µ–Ω—Ç—ã')

        download_filename = generate_filename("documents_report")

        return FileResponse(
            path=filepath,
            filename=download_filename,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")


@router.get("/documents-analysis")
async def save_documents_analysis():
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º

    Returns:
        FileResponse: Excel —Ñ–∞–π–ª —Å –∞–Ω–∞–ª–∏–∑–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

    Raises:
        HTTPException: 400 –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
        HTTPException: 500 –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        documents_data = data_manager.get_processed_data("documents_processed")

        if documents_data is None or documents_data.empty:
            raise HTTPException(status_code=400, detail="–î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents_data)} —Å—Ç—Ä–æ–∫, {len(documents_data.columns)} –∫–æ–ª–æ–Ω–æ–∫")

        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ Excel
        with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
            filepath = tmp_file.name

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ xlsxwriter
        save_with_xlsxwriter_formatting(documents_data, filepath, '–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤', data_type="documents")

        download_filename = generate_filename("documents_analysis")

        return FileResponse(
            path=filepath,
            filename=download_filename,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")


@router.get("/tasks")
async def save_tasks():
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ —Å—Ä–æ–∫–∞–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–µ–ª.

    –í—ã–ø–æ–ª–Ω—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤
    –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ Excel —Ñ–∞–π–ª —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

    Returns:
        FileResponse: Excel —Ñ–∞–π–ª —Å –∑–∞–¥–∞—á–∞–º–∏, –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏

    Raises:
        HTTPException: 400 –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
        HTTPException: 500 –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–ª–∏ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

    Note:
        –û–±–æ–≥–∞—â–µ–Ω–∏–µ –≤–∫–ª—é—á–∞–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤:
        - –î–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á: REQUEST_TYPE, COURT, BORROWER, CASE_NAME
        - –î–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã—Ö –∑–∞–¥–∞—á: REQUEST_TYPE, COURT_NAME, BORROWER, CASE_NAME
        –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫
    """
    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –∏–∑ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        tasks_data = data_manager.get_processed_data("tasks")

        if tasks_data is None or tasks_data.empty:
            raise HTTPException(status_code=400, detail="–î–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        print(f"üíæ –ù–∞—á–∏–Ω–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á: {len(tasks_data)} —Å—Ç—Ä–æ–∫, {len(tasks_data.columns)} –∫–æ–ª–æ–Ω–æ–∫")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∑–∞–¥–∞—á
        detailed_cleaned = data_manager.get_detailed_data()
        documents_cleaned = data_manager.get_documents_data()

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –∑–∞–¥–∞—á –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤
        if detailed_cleaned is not None or documents_cleaned is not None:
            try:
                tasks_data = add_source_columns_to_tasks(
                    tasks_data,
                    detailed_cleaned,
                    documents_cleaned
                )
                print(f"‚úÖ –ó–∞–¥–∞—á–∏ —É—Å–ø–µ—à–Ω–æ –æ–±–æ–≥–∞—â–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏")
            except Exception as enrich_error:
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –æ–±–æ–≥–∞—â–µ–Ω–∏—è
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∑–∞–¥–∞—á: {enrich_error}")
                print("‚ö†Ô∏è –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")
        else:
            print("‚ÑπÔ∏è –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–µ–∑ –æ–±–æ–≥–∞—â–µ–Ω–∏—è")

        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
        tasks_data = rename_columns_to_russian(tasks_data, data_type="tasks")

        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
            filepath = tmp_file.name

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º —á–µ—Ä–µ–∑ xlsxwriter
        save_with_xlsxwriter_formatting(tasks_data, filepath, '–ó–∞–¥–∞—á–∏', 'tasks')

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        download_filename = generate_filename("tasks")

        return FileResponse(
            path=filepath,
            filename=download_filename,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")

@router.get("/tasks-by-executor")
async def save_tasks_by_executor(responsibleExecutor: str):
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è –≤ Excel —Ñ–∞–π–ª.

    Args:
        responsibleExecutor (str): –ò–º—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∑–∞–¥–∞—á.

    Returns:
        FileResponse: Excel —Ñ–∞–π–ª —Å –∑–∞–¥–∞—á–∞–º–∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è, –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏

    Raises:
        HTTPException: 400 –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
        HTTPException: 500 –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–ª–∏ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        if not responsibleExecutor:
            raise HTTPException(status_code=400, detail="–ù–µ —É–∫–∞–∑–∞–Ω –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
        tasks_data = data_manager.get_processed_data("tasks")
        if tasks_data is None or tasks_data.empty:
            raise HTTPException(status_code=400, detail="–î–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—é
        tasks_data = tasks_data[tasks_data["responsibleExecutor"] == responsibleExecutor]
        if tasks_data.empty:
            raise HTTPException(
                status_code=400,
                detail=f"–ó–∞–¥–∞—á–∏ –¥–ª—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è '{responsibleExecutor}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            )

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è
        detailed_cleaned = data_manager.get_detailed_data()
        documents_cleaned = data_manager.get_documents_data()

        # –û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
        if detailed_cleaned is not None or documents_cleaned is not None:
            try:
                tasks_data = add_source_columns_to_tasks(
                    tasks_data,
                    detailed_cleaned,
                    documents_cleaned
                )
            except Exception as enrich_error:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∑–∞–¥–∞—á: {enrich_error}")
                print("‚ö†Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π
        tasks_data = rename_columns_to_russian(tasks_data, data_type="tasks")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        import tempfile
        with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
            filepath = tmp_file.name

        save_with_xlsxwriter_formatting(tasks_data, filepath, '–ó–∞–¥–∞—á–∏', 'tasks')

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        download_filename = generate_filename("tasks")

        return FileResponse(
            path=filepath,
            filename=download_filename,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á –¥–ª—è {responsibleExecutor}: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")

@router.get("/rainbow-analysis")
async def save_rainbow_analysis():
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Ä–∞–¥—É–≥–∏ —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

    –§—É–Ω–∫—Ü–∏—è —Ä–µ–∞–ª–∏–∑—É–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
    –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ Excel —Ñ–∞–π–ª —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
    –ø–æ –∫–æ–¥—É –¥–µ–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω–µ–¥–∂–µ—Ä–∞.

    Returns:
        FileResponse: Excel —Ñ–∞–π–ª —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ —Ä–∞–¥—É–≥–∏

    Raises:
        HTTPException: 400 –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
        HTTPException: 500 –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
        cleaned_df = data_manager._cleaned_data.get("detailed_report")
        if cleaned_df is None or cleaned_df.empty:
            raise HTTPException(status_code=400, detail="–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ derived –¥–∞–Ω–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        derived_df = data_manager._derived_data.get("detailed_rainbow")
        if derived_df is None or derived_df.empty:
            raise HTTPException(status_code=400, detail="–î–∞–Ω–Ω—ã–µ —Ü–≤–µ—Ç–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã")

        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–π –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É —Ç–∏–ø—É –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
        cleaned_key = COLUMNS["CASE_CODE"]
        derived_key = COLUMNS["CASE_CODE"]

        cleaned_df[cleaned_key] = cleaned_df[cleaned_key].astype(str).str.strip()
        derived_df[derived_key] = derived_df[derived_key].astype(str).str.strip()

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ –∫–æ–¥—É –¥–µ–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–µ–≤–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        # –õ–µ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        merged_df = cleaned_df.merge(
            derived_df[[derived_key, COLUMNS["CURRENT_PERIOD_COLOR"]]],
            how="left",
            left_on=cleaned_key,
            right_on=derived_key,
            suffixes=("", "_rainbow")
        )

        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫–∞–∫ FileResponse
        with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
            filepath = tmp_file.name

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        save_with_xlsxwriter_formatting(
            merged_df,
            filepath,
            sheet_name="–¶–≤–µ—Ç–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è",
            data_type="detailed"
        )

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —à–∞–±–ª–æ–Ω—É
        download_filename = generate_filename("rainbow_analysis")

        return FileResponse(
            path=filepath,
            filename=download_filename,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–¥—É–≥–∏: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")

@router.get("/terms-productions")
async def save_terms_productions():
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö —Å—Ä–æ–∫–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤ (–∏—Å–∫. –∏ –ø—Ä–∏–∫–∞–∑–Ω–æ–µ) –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª Excel.

    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏—Å–∫–æ–≤–æ–≥–æ –∏ –ø—Ä–∏–∫–∞–∑–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –≤ –æ–¥–∏–Ω –ª–∏—Å—Ç.
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π

    Returns:
        FileResponse: Excel —Ñ–∞–π–ª —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤

    Raises:
        HTTPException: 400 –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
        HTTPException: 500 –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–±–æ–∏—Ö —Ç–∏–ø–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤
        lawsuit_data = data_manager.get_processed_data("lawsuit_staged")
        order_data = data_manager.get_processed_data("order_staged")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö
        if (lawsuit_data is None or lawsuit_data.empty) and (order_data is None or order_data.empty):
            raise HTTPException(status_code=400, detail="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤")

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –æ–¥–∏–Ω DataFrame
        combined_data = pd.concat(
            [df for df in [lawsuit_data, order_data] if df is not None and not df.empty],
            ignore_index=True
        )

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ —Å—Ä–æ–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤: {len(combined_data)} —Å—Ç—Ä–æ–∫, {len(combined_data.columns)} –∫–æ–ª–æ–Ω–æ–∫")

        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ Excel
        with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
            filepath = tmp_file.name

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        save_with_xlsxwriter_formatting(combined_data, filepath, '–°—Ä–æ–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤', 'production')
        download_filename = generate_filename("terms_productions")

        return FileResponse(
            path=filepath,
            filename=download_filename,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")

@router.get("/all-analysis")
async def save_all_analysis():
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –≤–∏–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤ –æ–¥–∏–Ω ZIP-–∞—Ä—Ö–∏–≤.

    –°–æ–∑–¥–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞—Ä—Ö–∏–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã.
    –ò—Å–∫–æ–≤–æ–µ –∏ –ø—Ä–∏–∫–∞–∑–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –≤ –æ–¥–∏–Ω –ª–∏—Å—Ç '–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞'.

    Returns:
        FileResponse: ZIP –∞—Ä—Ö–∏–≤ —Å–æ –≤—Å–µ–º–∏ –æ—Ç—á–µ—Ç–∞–º–∏

    Raises:
        HTTPException: 400 –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        HTTPException: 500 –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞
    """
    import zipfile
    import os

    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è ZIP –∞—Ä—Ö–∏–≤–∞
        with tempfile.NamedTemporaryFile(suffix=".zip", delete=False) as tmp_zip_file:
            zip_filepath = tmp_zip_file.name

        files_to_zip = []
        temp_files = []

        try:
            # –ü–æ–ª—É—á–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            terms_productions_data = pd.concat(
                [df for df in [
                    data_manager.get_processed_data("lawsuit_staged"),
                    data_manager.get_processed_data("order_staged")
                ] if df is not None and not df.empty],
                ignore_index=True
            ) if (data_manager.get_processed_data("lawsuit_staged") is not None or
                  data_manager.get_processed_data("order_staged") is not None) else None

            documents_analysis_data = data_manager.get_processed_data("documents_processed")
            tasks_data = data_manager.get_processed_data("tasks")
            rainbow_data = data_manager.get_colored_data("detailed")

            # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
            data_sources = {
                "terms_productions": {
                    "data": terms_productions_data,
                    "sheet_name": "–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞",
                    "data_type": "production"
                },
                "documents_analysis": {
                    "data": documents_analysis_data,
                    "sheet_name": "–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
                    "data_type": "documents"
                },
                "tasks": {
                    "data": tasks_data,
                    "sheet_name": "–ó–∞–¥–∞—á–∏",
                    "data_type": "tasks"
                },
                "rainbow_analysis": {
                    "data": rainbow_data,
                    "sheet_name": "–†–∞–¥—É–≥–∞",
                    "data_type": "detailed"
                }
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            for key, cfg in data_sources.items():
                data = cfg["data"]
                sheet_name = cfg["sheet_name"]
                data_type = cfg["data_type"]

                if data is not None and not data.empty:
                    with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
                        filepath = tmp_file.name
                        temp_files.append(filepath)

                    save_with_xlsxwriter_formatting(data, filepath, sheet_name, data_type)
                    files_to_zip.append((filepath, f"{key}.xlsx"))
                    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –≤ –∞—Ä—Ö–∏–≤: {sheet_name}")
                else:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {sheet_name} - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")

            if not files_to_zip:
                raise HTTPException(status_code=400, detail="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")

            # –°–æ–∑–¥–∞–µ–º ZIP –∞—Ä—Ö–∏–≤
            with zipfile.ZipFile(zip_filepath, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path, archive_name in files_to_zip:
                    zipf.write(file_path, archive_name)

            download_filename = generate_filename("all_analysis") + ".zip"

            return FileResponse(
                path=zip_filepath,
                filename=download_filename,
                media_type='application/zip'
            )

        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            for file_path in temp_files:
                try:
                    if os.path.exists(file_path):
                        os.unlink(file_path)
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {file_path}: {e}")

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤: {e}")
        try:
            if os.path.exists(zip_filepath):
                os.unlink(zip_filepath)
        except:
            pass
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞: {str(e)}")