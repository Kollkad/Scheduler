# backend/app/common/tests/auto/unique_columns_test.py
#TODO: –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å —Ç–µ—Å—Ç, –æ—à–∏–±–∫–∞
"""
–¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–ª–æ–Ω–æ–∫ –≤ –¥–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö:
- –ö–æ–¥ –ø–µ—Ä–µ–¥–∞—á–∏, –ö–æ–¥ –∑–∞–ø—Ä–æ—Å–∞, –ö–æ–¥ –¥–µ–ª–∞
–ò—â–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫
"""

import os
import sys
from typing import Dict

import pandas as pd

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../..'))

from backend.app.common.modules.data_import import load_excel_data
from backend.app.common.modules.data_clean_documents import clean_documents_data
from backend.app.common.tests.tests_config import TestsConfig


def run():
    """
    –¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–ª–æ–Ω–æ–∫ –≤ –¥–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

    Returns:
        bool: True –µ—Å–ª–∏ —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω —É—Å–ø–µ—à–Ω–æ
    """
    print("\n" + "=" * 60)
    print("üîç –¢–ï–°–¢ –ü–†–û–í–ï–†–ö–ò –£–ù–ò–ö–ê–õ–¨–ù–û–°–¢–ò –ö–û–õ–û–ù–û–ö")
    print("=" * 60)

    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print("\nüìÅ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –î–û–ö–£–ú–ï–ù–¢–û–í...")
        file_path = TestsConfig.TEST_FILES["documents"]

        if not file_path.exists():
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return False

        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        print("\nüîé –ü–†–û–í–ï–†–ö–ê –û–°–ù–û–í–ù–´–• –ö–û–õ–û–ù–û–ö...")
        uniqueness_results = check_column_uniqueness(str(file_path))

        if "error" in uniqueness_results:
            print(f"‚ùå –û—à–∏–±–∫–∞: {uniqueness_results['error']}")
            return False

        print_uniqueness_results(uniqueness_results)

        # 3. –ü–æ–∏—Å–∫ –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        print("\nüéØ –ü–û–ò–°–ö –£–ù–ò–ö–ê–õ–¨–ù–´–• –ò–î–ï–ù–¢–ò–§–ò–ö–ê–¢–û–†–û–í...")
        identifier_results = find_unique_identifier(str(file_path))

        if "error" in identifier_results:
            print(f"‚ùå –û—à–∏–±–∫–∞: {identifier_results['error']}")
            return False

        print_identifier_results(identifier_results)

        # –¢–µ—Å—Ç —Å—á–∏—Ç–∞–µ—Ç—Å—è —É—Å–ø–µ—à–Ω—ã–º –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
        success = True
        if success:
            print("\n‚úÖ –¢–ï–°–¢ –ü–†–û–í–ï–†–ö–ò –£–ù–ò–ö–ê–õ–¨–ù–û–°–¢–ò –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
        else:
            print("\n‚ö†Ô∏è –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù –° –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø–ú–ò")

        return success

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ: {e}")
        import traceback
        traceback.print_exc()
        return False


def check_column_uniqueness(filepath: str) -> Dict[str, Dict]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö '–ö–æ–¥ –ø–µ—Ä–µ–¥–∞—á–∏', '–ö–æ–¥ –∑–∞–ø—Ä–æ—Å–∞', '–ö–æ–¥ –¥–µ–ª–∞'
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        raw_df = load_excel_data(filepath)
        cleaned_df = clean_documents_data(raw_df)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_columns = ['–ö–æ–¥ –ø–µ—Ä–µ–¥–∞—á–∏', '–ö–æ–¥ –∑–∞–ø—Ä–æ—Å–∞', '–ö–æ–¥ –¥–µ–ª–∞']
        missing_columns = [col for col in required_columns if col not in cleaned_df.columns]

        if missing_columns:
            return {"error": f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}"}

        results = {}

        for column in required_columns:
            # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–ª–æ–Ω–∫–∏ (–∏—Å–∫–ª—é—á–∞—è NaN)
            values = cleaned_df[column].dropna()
            total_values = len(values)
            unique_values = values.nunique()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å
            is_unique = unique_values == total_values
            duplicate_count = total_values - unique_values

            results[column] = {
                'total_values': total_values,
                'unique_values': unique_values,
                'is_unique': is_unique,
                'duplicate_count': duplicate_count,
                'duplicate_percentage': (duplicate_count / total_values * 100) if total_values > 0 else 0
            }

            # –ï—Å–ª–∏ –µ—Å—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã, –Ω–∞—Ö–æ–¥–∏–º –ø—Ä–∏–º–µ—Ä—ã
            if duplicate_count > 0:
                duplicates = values[values.duplicated(keep=False)]
                results[column]['duplicate_examples'] = duplicates.head(3).tolist()

        return results

    except Exception as e:
        return {"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}"}


def find_unique_identifier(filepath: str) -> Dict:
    """
    –ò—â–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫
    """
    try:
        raw_df = load_excel_data(filepath)
        cleaned_df = clean_documents_data(raw_df)

        results = {}
        unique_columns = []

        for column in cleaned_df.columns:
            try:
                values = cleaned_df[column]

                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫ Series –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if hasattr(values, 'tolist'):
                    values_series = values
                else:
                    values_series = pd.Series(values)

                values_clean = values_series.dropna()
                total_values = len(values_clean)

                if total_values == 0:
                    continue

                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                try:
                    unique_values = values_clean.nunique()
                except:
                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± —á–µ—Ä–µ–∑ set
                    unique_values = len(set(values_clean.astype(str)))

                is_unique = (unique_values == total_values)

                results[column] = {
                    'is_unique': is_unique,
                    'total_values': total_values,
                    'unique_values': unique_values,
                    'duplicate_count': total_values - unique_values
                }

                if is_unique:
                    unique_columns.append(column)

            except Exception as col_error:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ {column}: {col_error}")
                continue

        return {
            'all_columns': results,
            'unique_columns': unique_columns,
            'recommendation': f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã: {unique_columns}" if unique_columns else "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫"
        }

    except Exception as e:
        return {"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {str(e)}"}


def print_uniqueness_results(results):
    """
    –í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
    """
    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–í–ï–†–ö–ò –£–ù–ò–ö–ê–õ–¨–ù–û–°–¢–ò:")
    print("-" * 70)
    print(f"{'–ö–æ–ª–æ–Ω–∫–∞':<15} {'–£–Ω–∏–∫–∞–ª—å–Ω–∞':<10} {'–í—Å–µ–≥–æ':<8} {'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö':<12} {'–î—É–±–ª–∏–∫–∞—Ç–æ–≤':<12} {'% –î—É–±–ª–∏–∫–∞—Ç–æ–≤':<12}")
    print("-" * 70)

    for column, stats in results.items():
        status = "‚úÖ" if stats['is_unique'] else "‚ùå"
        print(f"{column:<15} {status:<10} {stats['total_values']:<8} {stats['unique_values']:<12} "
              f"{stats['duplicate_count']:<12} {stats['duplicate_percentage']:.1f}%")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –µ—Å–ª–∏ –µ—Å—Ç—å
        if stats['duplicate_count'] > 0 and 'duplicate_examples' in stats:
            examples = ", ".join(map(str, stats['duplicate_examples'][:2]))
            print(f"                 –ü—Ä–∏–º–µ—Ä—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {examples}...")


def print_identifier_results(results):
    """
    –í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
    """
    unique_columns = results['unique_columns']

    print(f"\nüéØ –ù–ê–ô–î–ï–ù–û –£–ù–ò–ö–ê–õ–¨–ù–´–• –ö–û–õ–û–ù–û–ö: {len(unique_columns)}")

    if unique_columns:
        print("‚úÖ –ö–æ–ª–æ–Ω–∫–∏ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏:")
        for i, column in enumerate(unique_columns, 1):
            stats = results['all_columns'][column]
            print(f"   {i}. {column} ({stats['total_values']} –∑–Ω–∞—á–µ–Ω–∏–π)")
    else:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 –∫–æ–ª–æ–Ω–æ–∫ —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    print(f"\nüèÜ –¢–û–ü-5 –ö–û–õ–û–ù–û–ö –° –ù–ê–ò–ú–ï–ù–¨–®–ò–ú –ö–û–õ–ò–ß–ï–°–¢–í–û–ú –î–£–ë–õ–ò–ö–ê–¢–û–í:")
    all_columns = []
    for column, stats in results['all_columns'].items():
        if stats['total_values'] > 0:
            duplicate_pct = (stats['duplicate_count'] / stats['total_values']) * 100
            all_columns.append((column, duplicate_pct, stats['total_values']))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    all_columns.sort(key=lambda x: x[1])

    for i, (column, duplicate_pct, total) in enumerate(all_columns[:5], 1):
        status = "‚úÖ" if duplicate_pct == 0 else "‚ö†Ô∏è"
        print(f"   {i}. {column}: {duplicate_pct:.1f}% –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ({total} –∑–Ω–∞—á–µ–Ω–∏–π) {status}")


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω—Å–æ–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
def run_console(**kwargs):
    """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –≤ –∫–æ–Ω—Å–æ–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ"""
    return run()


if __name__ == "__main__":
    success = run()
    sys.exit(0 if success else 1)